### Gradient Descent Optimization
In this project, we implement a 3-layer fully-connected neural network to classify the fashion-MNIST dataset using No Momentum, Polyak’s classical momentum, Nesterov’s Accelerated Gradient, RmsProp and ADAM algorithms

### Usage
Run `starter.py` as:
`python starter.py`

### Training Result
#### Accuracy
![x](https://raw.githubusercontent.com/shenweihai1/imageUrlService/master/inlearning/acc.png)
#### Neural network structure for the experiments
![x](https://raw.githubusercontent.com/shenweihai1/imageUrlService/master/inlearning/exp.png)

#### Loss curve
![x](https://raw.githubusercontent.com/shenweihai1/imageUrlService/master/inlearning/loss.png)
#### Predictions using NO_MOMENTUM
![x](https://raw.githubusercontent.com/shenweihai1/imageUrlService/master/inlearning/config01.png)
#### Predictions using MOMENTUM
![x](https://raw.githubusercontent.com/shenweihai1/imageUrlService/master/inlearning/config02.png)
#### Predictions using NESTEROV
![x](https://raw.githubusercontent.com/shenweihai1/imageUrlService/master/inlearning/config03.png)
#### Predictions using RMSPROP
![x](https://raw.githubusercontent.com/shenweihai1/imageUrlService/master/inlearning/config04.png)
#### Predictions using ADAM
![x](https://raw.githubusercontent.com/shenweihai1/imageUrlService/master/inlearning/config05.png)

