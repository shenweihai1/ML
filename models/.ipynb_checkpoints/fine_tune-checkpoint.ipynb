{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'Q_1': 14})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "import collections\n",
    "import re\n",
    "\n",
    "split_words = lambda s: s.split() \n",
    "strip_space = lambda s: re.sub(\"\\s+\", \" \", re.sub(\"\\s+\\?\", \"?\", re.sub(\"\\s+\\.\", \".\", re.sub(\"\\s+,\", \".\", s)))).lstrip().rstrip().replace(\"..\", \".\")\n",
    "\n",
    "def load_examples(file_name: str):\n",
    "    ans = []\n",
    "    err = collections.defaultdict(int)\n",
    "    with open(file_name, 'r') as handler:\n",
    "        for line in handler:\n",
    "            example = json.loads(line)\n",
    "            question = example['question']\n",
    "            example = json.loads(line)\n",
    "            question = example['question']\n",
    "            \n",
    "            #if example['id'] != 'QuaRel_V1_B4_0325':\n",
    "            #    continue\n",
    "            \n",
    "            if \"(A)\" not in question or \"(B)\" not in question:\n",
    "                err['A_B'] += 1\n",
    "                continue \n",
    "                \n",
    "            idx = question.index(\"(A)\")\n",
    "            Q, second = question[0:idx], question[idx:]\n",
    "                \n",
    "            ans_idx = second.index(\"(B)\")\n",
    "            ans_first, ans_second = second[0:ans_idx].replace(\"(A)\", \"\"), second[ans_idx:].replace(\"(B)\", \"\")\n",
    "            ans_first = re.sub(\"or\\s*$\", \"\", ans_first)\n",
    "            ans_second = re.sub(\"or\\s*$\", \"\", ans_second)\n",
    "            \n",
    "            A = ans_first if example.get(\"answer_index\", 0) == 0 else ans_second\n",
    "            \n",
    "            if \"_____\" in Q:\n",
    "                Q = Q.replace(\"_____\", A)\n",
    "            else:\n",
    "                Q = \"{0} {1}.\".format(Q, A)\n",
    "            \n",
    "            # split it into two sentence\n",
    "            Q = re.sub(\" +\", \" \", Q)\n",
    "            \n",
    "            Q_items = re.split(\"(\\.|\\?\", Q)\n",
    "            Q_items_process = []\n",
    "            for i in range(len(Q_items)):\n",
    "                if Q_items[i] == '.' or Q_items[i] == '?':\n",
    "                    Q_items_process[-1] = \"{0}{1}\".format(Q_items_process[-1], Q_items[i])\n",
    "                else:\n",
    "                    if Q_items[i]:\n",
    "                        Q_items_process.append(Q_items[i])\n",
    "    \n",
    "            Q_items = [i for i in Q_items_process if i]\n",
    " \n",
    "            Q_1, Q_2 = [], []\n",
    "            threshold, tmp_w = 5, 0\n",
    "            for idx, s in enumerate(Q_items[::-1]):\n",
    "                if tmp_w <= threshold:\n",
    "                    Q_2.append(s)\n",
    "                else:\n",
    "                    Q_1.append(s)\n",
    "                tmp_w += len(split_words(s))\n",
    "                            \n",
    "            Q_1 = \" \".join(Q_1[::-1]).rstrip()\n",
    "            Q_2 = \" \".join(Q_2[::-1]).rstrip()\n",
    "            if not Q_1:\n",
    "                Qs = re.split(\"(it\\s+\\w+|due to|so|because|and\\s+\\w+|it became|and it|this means|since|\\?\\s+|\\.\\s+|,\\s+|but|it appeared)\", Q_2)\n",
    "                Q_1, Q_2 = \" \".join(Qs[0:-2]), \" \".join(Qs[-2:])\n",
    "                Q_2 = re.sub(\",\\s+|\\.\\s+|\\?\\s+\", \"\", Q_2)\n",
    "            \n",
    "            if not Q_2:\n",
    "                err[\"Q_2\"] += 1\n",
    "            \n",
    "            if not Q_1:\n",
    "                err[\"Q_1\"] += 1\n",
    "            \n",
    "            item = {\n",
    "                \"Q\": question,\n",
    "                \"id\": example['id'],\n",
    "                \"Q_1\": strip_space(Q_1),\n",
    "                \"Q_2\": strip_space(Q_2),\n",
    "            }\n",
    "            \n",
    "            ans.append(item)\n",
    "    print(err)\n",
    "    return ans\n",
    "\n",
    "ans = load_examples(join(BASE_PATH, \"quarel-data\", \"quarel-v1-train.json\"))\n",
    "\n",
    "w = open(\"corpus.txt\", \"w\")\n",
    "for a in ans:\n",
    "    if not a[\"Q_1\"]: \n",
    "        continue\n",
    "        \n",
    "    #w.write(\"{0}\\n\".format(a['id']))\n",
    "    #w.write(\"{0}\\n\".format(a['Q']))\n",
    "    w.write(\"{0}\\n\".format(a['Q_1']))\n",
    "    w.write(\"{0}\\n\\n\".format(a['Q_2']))\n",
    "    #w.write(\"========\\n\\n\")\n",
    "w.close()\n",
    "\n",
    "# pprint.pprint(ans[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file ./pytorch-bert/finetuned_lm/vocab.txt\n",
      "INFO:pytorch_pretrained_bert.modeling:loading archive file ./pytorch-bert/finetuned_lm/\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'car', 'gets', 'very', 'hot', 'as', 'it', 'drives', 'up', 'a', 'muddy', 'hill', ',', 'but', 'stays', 'cool', 'as', 'it', 'drives', 'up', 'a', 'grass', 'hill', '.', 'the', 'car', 'warm', '##s', 'on', 'on', 'the', 'muddy', 'hill', 'because', 'the', 'muddy', 'hill', 'has', \"'\", ',', \"'\", 'r', '_', 'q', \"'\", ':', \"'\", '[', 'cl', '##s', ']', 'a', 'car', 'gets', 'very', 'hot', 'as', 'it', 'drives', 'up', 'a', 'muddy', 'hill', ',', 'but', 'stays', 'cool', 'as', 'it', 'drives', 'up', 'a', 'grass', 'hill', '.', 'the', 'car', 'warm', '##s', 'on', 'on', 'the', 'muddy', 'hill', '[SEP]', 'because', 'the', 'muddy', 'hill', 'has', 'less', 'friction', '[SEP]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "tensor([[ 7.1011, -6.1035]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.0000e+00, 1.8422e-06]], grad_fn=<SoftmaxBackward>)\n",
      "END\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/anaconda3/envs/python_37/lib/python3.7/site-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# try the predict next sentence model\n",
    "# https://github.com/huggingface/pytorch-pretrained-BERT/issues/48\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM,BertForNextSentencePrediction,BertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "model_name = './pytorch-bert/finetuned_lm/'\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "text = \"A car gets very hot as it drives up a muddy hill, but stays cool as it drives up a grass hill. The car warms on on the muddy hill because the muddy hill has ', 'R_Q': '[CLS] A car gets very hot as it drives up a muddy hill, but stays cool as it drives up a grass hill. The car warms on on the muddy hill [SEP] because the muddy hill has less friction [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertForNextSentencePrediction.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "print(\"START\")\n",
    "# Predict is Next Sentence ?\n",
    "predictions = model(tokens_tensor, segments_tensors )\n",
    "\n",
    "print(predictions)\n",
    "print(F.softmax(predictions))\n",
    "# https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py\n",
    "print(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
